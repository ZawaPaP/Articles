---
title: PythonのCeleryを試してみた
tags:
  - Python
  - Celery
private: false
updated_at: '2024-08-25T00:45:22+09:00'
id: f6f74ea4479e89f23214
organization_url_name: null
slide: false
ignorePublish: false
---
## これは何?
- pythonのCeleryパッケージをローカルにて動かしてみます。
- 今回はDockerのRedisを使用し、Celeryが動作することを確認できました。


### Celeryとは

 Celeryのイメージ

![Celery.drawio.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/386347/5c2dbda5-71cc-2002-11d9-02c2e0a70102.png)


- Task
    - Celeryでの実行のために作成されるタスク。
- Broker
    - 作成されたタスクの置き場所。タスクはWorkerに実行されるまで、ここで待機する。
- Worker
    - Brokerからタスクを持ってきて実行する。Celeryのインスタンスが役割を担う。
- Backend
    - 実行されたタスクの結果を保存する場所。

図にもある通り、Celeryを実行するWorkerはTaskを作成するAppとは別になります。そのため、Appと分けた非同期処理を簡単に実現することができます。

### Celeryの実装

今回は、brokerとBackendにRedisを利用します。

以下の4つをそれぞれDockerとして作成します。

- Taskを作成する元のpython Application
- Broker、BackendとなるRedis
- Celery workerを実行するpython環境
- Celeryのモニターを行う `flower` を実行するpython環境

### 実際に試してみる

Githubディレクトリからコードをクローンし、以下を実行します。

https://github.com/ZawaPaP/Celery-demo

```jsx
// dockerを立ち上げ
docker compose up --build

// python実行コンテナに入る
docker exec -it [container ID] bash

// python実行コンテナでTaskを実行してみる
python create_first_task.py
```

Flowerでworkerの確認ができます。
タスクの詳細も確認可能です。

[`http://localhost:5555/`](http://localhost:5555/)

![スクリーンショット 2024-08-24 22.12.52.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/386347/92eab890-0257-97f0-6a79-dbc043b541d3.png)


---
続いて非同期処理していることも確認してみます。

以下のタスクは10秒sleepして returnする関数を2回実行します。

```jsx
python create_multi_task.py

// stdout
First task added to queue
Second task added to queue
```

実行してすぐにFlowerを見ると、タスクが `Active` 状態となっており、 `Succeed` になっていないことがわかります。

![スクリーンショット 2024-08-24 23.55.50.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/386347/c3c1d3d5-3f16-5646-2324-3a29685848e2.png)



今回はCeleryを使ってみることがゴールのため、ここまでとしますが実際には、Celeryの様々な機能を追加していくことができます。
Celeryは業務でも使用するため、今後より詳細を調べる時間も取れればと思います。
